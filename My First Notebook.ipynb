{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "training_iteration = 20\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(image):\n",
    "    return ((image/255)-0.5)\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "def unpickle_all(path):\n",
    "    train_images = np.zeros((20000,32,32,3))\n",
    "    test_images = np.zeros((10000,32,32,3))\n",
    "    train_labels = np.zeros((20000))\n",
    "    test_labels = np.zeros((10000))\n",
    "    for i in range(1,3):\n",
    "        j = i-1\n",
    "        cifar10 = unpickle(path+'/data_batch_{}'.format(i))\n",
    "        train_labels[j*10000:(j+1)*10000] = cifar10['labels']\n",
    "        data = scale_img(cifar10['data'])\n",
    "        train_images[j*10000:(j+1)*10000,:,:,:] =np.swapaxes(np.reshape(data,(10000,32,32,3), order='F'),axis1=1,axis2=2)\n",
    "\n",
    "    cifar10 = unpickle(path + '/test_batch')\n",
    "    test_labels[:] = cifar10['labels']\n",
    "    data = scale_img(cifar10['data'])\n",
    "    test_images = np.swapaxes(np.reshape(data, (10000, 32, 32, 3), order='F'),axis1=1,axis2=2)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, test_images, test_labels = unpickle_all('./storage/CIFAR-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ad8a2b94ab10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cost_function\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder('float32', [None,32,32,3],name = 'X')\n",
    "y = tf.placeholder('int64', [None,], name = \"Y\")\n",
    "W_CL_1 = tf.Variable(np.random.randn(3, 3, 3, 128), dtype=\"float32\")\n",
    "W_CL_2 = tf.Variable(np.random.randn(3, 3, 128, 256),dtype=\"float32\")\n",
    "\n",
    "with tf.name_scope(\"CL1\") as scope:\n",
    "    CL_1 = tf.nn.conv2d(x,W_CL_1,strides = [1,1,1,1], padding=\"SAME\")\n",
    "    RELU_1 = tf.nn.relu(CL_1)    \n",
    "    #MAXPOOL_1 = tf.nn.max_pool(RELU_1,ksize=(1,2,2,1),strides=(1,2,2,1),padding=\"VALID\")\n",
    "    \n",
    "with tf.name_scope(\"CL2\") as scope:\n",
    "    CL_2 = tf.nn.conv2d(RELU_1,W_CL_2,strides = [1,1,1,1], padding=\"SAME\")\n",
    "    RELU_2 = tf.nn.relu(CL_2)\n",
    "    MAXPOOL_2 = tf.nn.max_pool(RELU_2,ksize=(1,2,2,1),strides=(1,2,2,1),padding=\"VALID\")\n",
    "    DROPOUT_2 = tf.nn.dropout(MAXPOOL_2,0.25)\n",
    "    FLAT_2 = tf.layers.flatten(DROPOUT_2)\n",
    "\n",
    "with tf.name_scope(\"DENSE_1\") as scope:\n",
    "    DENSE_3 = tf.contrib.layers.fully_connected(FLAT_2,2048)\n",
    "    #DROPOUT_3 = tf.nn.dropout(DENSE_3,0.5)\n",
    "\n",
    "with tf.name_scope(\"PREDICTIONS\") as scope:\n",
    "    LOGITS_4 = tf.contrib.layers.fully_connected(DENSE_3,10, activation_fn = None)\n",
    "    y_hat = tf.nn.softmax(LOGITS_4)\n",
    "    predictions = tf.argmax(y_hat, 1)\n",
    "\n",
    "with tf.name_scope(\"ACCURACY\") as scope:\n",
    "    compare = tf.equal(predictions, y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(compare, \"float\"))\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "with tf.name_scope(\"LOSS\") as scope:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y, depth=10),logits=LOGITS_4))\n",
    "    tf.summary.scalar(\"cost_function\", loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-9248dd57ae90>\", line 16, in <module>\n",
      "    _, cost, summary_str = sess.run([optimizer, loss, merged_summary_op], feed_dict={x: batch_xs, y: batch_ys})\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 877, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1100, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1272, in _do_run\n",
      "    run_metadata)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 233, in __init__\n",
      "    def __init__(self, node_def, op, message):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\quentin\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 734, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    sess.run(init)\n",
    "    summary_writer = tf.summary.FileWriter('data/logs', graph_def=sess.graph_def)\n",
    "    # Training cycle\n",
    "    for iteration in range(training_iteration):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(images.shape[0] / batch_size)\n",
    "        # Loop over all batches\n",
    "        total_batch_time = 0.\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            start_batch = tm.time()\n",
    "            batch_xs = images[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "            batch_ys = labels[i*batch_size:(i+1)*batch_size]\n",
    "            _, cost, summary_str = sess.run([optimizer, loss, merged_summary_op], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += cost/batch_size/total_batch\n",
    "            summary_writer.add_summary(summary_str, iteration * total_batch + i)\n",
    "            '''\n",
    "            stop_batch = tm.time()\n",
    "            batch_time = stop_batch - start_batch\n",
    "            total_batch_time += batch_time\n",
    "            avg_batch_time = total_batch_time / (i+1)\n",
    "            print(\"Batch #{}, Batch time: {}, Avg batch time: {}\".format(i+1, batch_time, avg_batch_time))\n",
    "            '''\n",
    "        if iteration % display_step == 0:\n",
    "            test_accuracy = sess.run([accuracy], feed_dict={x: test_images, y: test_labels})\n",
    "            print(\"Iteration: {}  Cost= {}  Train accuracy= {}%\".format(iteration, avg_cost, test_accuracy[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
